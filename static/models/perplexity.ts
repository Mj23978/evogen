// Auto-generated model configuration
// Generated on 2025-06-28T19:02:34.499Z

import { ModelInfo } from '../../core/types';

const models: ModelInfo[] = [
  {
    "name": "codellama-34b-instruct",
    "label": "codellama 34b instruct",
    "provider": "Perplexity",
    "type": "chat",
    "modalities": [],
    "context": {
      "maxTokens": 16384,
      "maxInputTokens": 16384,
      "maxOutputTokens": 16384
    },
    "cost": {
      "inputCost": 0.35,
      "outputCost": 1.4
    },
    "metadata": {}
  },
  {
    "name": "codellama-70b-instruct",
    "label": "codellama 70b instruct",
    "provider": "Perplexity",
    "type": "chat",
    "modalities": [],
    "context": {
      "maxTokens": 16384,
      "maxInputTokens": 16384,
      "maxOutputTokens": 16384
    },
    "cost": {
      "inputCost": 0.7,
      "outputCost": 2.8
    },
    "metadata": {}
  },
  {
    "name": "llama-3.1-70b-instruct",
    "label": "llama 3.1 70b instruct",
    "provider": "Perplexity",
    "type": "chat",
    "modalities": [],
    "context": {
      "maxTokens": 131072,
      "maxInputTokens": 131072,
      "maxOutputTokens": 131072
    },
    "cost": {
      "inputCost": 1,
      "outputCost": 1
    },
    "metadata": {}
  },
  {
    "name": "llama-3.1-8b-instruct",
    "label": "llama 3.1 8b instruct",
    "provider": "Perplexity",
    "type": "chat",
    "modalities": [],
    "context": {
      "maxTokens": 131072,
      "maxInputTokens": 131072,
      "maxOutputTokens": 131072
    },
    "cost": {
      "inputCost": 0.2,
      "outputCost": 0.2
    },
    "metadata": {}
  },
  {
    "name": "llama-3.1-sonar-huge-128k-online",
    "label": "llama 3.1 sonar huge 128k online",
    "provider": "Perplexity",
    "type": "chat",
    "modalities": [],
    "context": {
      "maxTokens": 127072,
      "maxInputTokens": 127072,
      "maxOutputTokens": 127072
    },
    "cost": {
      "inputCost": 5,
      "outputCost": 5
    },
    "metadata": {}
  },
  {
    "name": "llama-3.1-sonar-large-128k-online",
    "label": "llama 3.1 sonar large 128k online",
    "provider": "Perplexity",
    "type": "chat",
    "modalities": [],
    "context": {
      "maxTokens": 127072,
      "maxInputTokens": 127072,
      "maxOutputTokens": 127072
    },
    "cost": {
      "inputCost": 1,
      "outputCost": 1
    },
    "metadata": {}
  },
  {
    "name": "llama-3.1-sonar-large-128k-chat",
    "label": "llama 3.1 sonar large 128k chat",
    "provider": "Perplexity",
    "type": "chat",
    "modalities": [],
    "context": {
      "maxTokens": 131072,
      "maxInputTokens": 131072,
      "maxOutputTokens": 131072
    },
    "cost": {
      "inputCost": 1,
      "outputCost": 1
    },
    "metadata": {}
  },
  {
    "name": "llama-3.1-sonar-small-128k-chat",
    "label": "llama 3.1 sonar small 128k chat",
    "provider": "Perplexity",
    "type": "chat",
    "modalities": [],
    "context": {
      "maxTokens": 131072,
      "maxInputTokens": 131072,
      "maxOutputTokens": 131072
    },
    "cost": {
      "inputCost": 0.2,
      "outputCost": 0.2
    },
    "metadata": {}
  },
  {
    "name": "llama-3.1-sonar-small-128k-online",
    "label": "llama 3.1 sonar small 128k online",
    "provider": "Perplexity",
    "type": "chat",
    "modalities": [],
    "context": {
      "maxTokens": 127072,
      "maxInputTokens": 127072,
      "maxOutputTokens": 127072
    },
    "cost": {
      "inputCost": 0.2,
      "outputCost": 0.2
    },
    "metadata": {}
  },
  {
    "name": "sonar",
    "label": "sonar",
    "provider": "Perplexity",
    "type": "chat",
    "modalities": [],
    "context": {
      "maxTokens": 127072,
      "maxInputTokens": 127072,
      "maxOutputTokens": 127072
    },
    "cost": {
      "inputCost": 1,
      "outputCost": 1
    },
    "metadata": {}
  },
  {
    "name": "sonar-pro",
    "label": "sonar pro",
    "provider": "Perplexity",
    "type": "chat",
    "modalities": [],
    "context": {
      "maxTokens": 200000,
      "maxInputTokens": 200000,
      "maxOutputTokens": 8096
    },
    "cost": {
      "inputCost": 3,
      "outputCost": 15
    },
    "metadata": {}
  },
  {
    "name": "pplx-7b-chat",
    "label": "pplx 7b chat",
    "provider": "Perplexity",
    "type": "chat",
    "modalities": [],
    "context": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192
    },
    "cost": {
      "inputCost": 0.07,
      "outputCost": 0.28
    },
    "metadata": {}
  },
  {
    "name": "pplx-70b-chat",
    "label": "pplx 70b chat",
    "provider": "Perplexity",
    "type": "chat",
    "modalities": [],
    "context": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096
    },
    "cost": {
      "inputCost": 0.7,
      "outputCost": 2.8
    },
    "metadata": {}
  },
  {
    "name": "pplx-7b-online",
    "label": "pplx 7b online",
    "provider": "Perplexity",
    "type": "chat",
    "modalities": [],
    "context": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096
    },
    "cost": {
      "outputCost": 0.28
    },
    "metadata": {}
  },
  {
    "name": "pplx-70b-online",
    "label": "pplx 70b online",
    "provider": "Perplexity",
    "type": "chat",
    "modalities": [],
    "context": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096
    },
    "cost": {
      "outputCost": 2.8
    },
    "metadata": {}
  },
  {
    "name": "llama-2-70b-chat",
    "label": "llama 2 70b chat",
    "provider": "Perplexity",
    "type": "chat",
    "modalities": [],
    "context": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096
    },
    "cost": {
      "inputCost": 0.7,
      "outputCost": 2.8
    },
    "metadata": {}
  },
  {
    "name": "mistral-7b-instruct",
    "label": "mistral 7b instruct",
    "provider": "Perplexity",
    "type": "chat",
    "modalities": [],
    "context": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096
    },
    "cost": {
      "inputCost": 0.07,
      "outputCost": 0.28
    },
    "metadata": {}
  },
  {
    "name": "mixtral-8x7b-instruct",
    "label": "mixtral 8x7b instruct",
    "provider": "Perplexity",
    "type": "chat",
    "modalities": [],
    "context": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096
    },
    "cost": {
      "inputCost": 0.07,
      "outputCost": 0.28
    },
    "metadata": {}
  },
  {
    "name": "sonar-small-chat",
    "label": "sonar small chat",
    "provider": "Perplexity",
    "type": "chat",
    "modalities": [],
    "context": {
      "maxTokens": 16384,
      "maxInputTokens": 16384,
      "maxOutputTokens": 16384
    },
    "cost": {
      "inputCost": 0.07,
      "outputCost": 0.28
    },
    "metadata": {}
  },
  {
    "name": "sonar-small-online",
    "label": "sonar small online",
    "provider": "Perplexity",
    "type": "chat",
    "modalities": [],
    "context": {
      "maxTokens": 12000,
      "maxInputTokens": 12000,
      "maxOutputTokens": 12000
    },
    "cost": {
      "outputCost": 0.28
    },
    "metadata": {}
  },
  {
    "name": "sonar-medium-chat",
    "label": "sonar medium chat",
    "provider": "Perplexity",
    "type": "chat",
    "modalities": [],
    "context": {
      "maxTokens": 16384,
      "maxInputTokens": 16384,
      "maxOutputTokens": 16384
    },
    "cost": {
      "inputCost": 0.6,
      "outputCost": 1.8
    },
    "metadata": {}
  },
  {
    "name": "sonar-medium-online",
    "label": "sonar medium online",
    "provider": "Perplexity",
    "type": "chat",
    "modalities": [],
    "context": {
      "maxTokens": 12000,
      "maxInputTokens": 12000,
      "maxOutputTokens": 12000
    },
    "cost": {
      "outputCost": 1.8
    },
    "metadata": {}
  }
];

export default models;
